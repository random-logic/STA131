# Conditional Probabililty
* Let A and B be events P(B) > 0
* $P(A|B) = \frac{P(A \cap B)}{P(B)}$

# Multiplication Laws
1. $P(A \cap B) = P(A|B)P(B)$
2. Let $A_1$ through $A_n$ be a sequence of events
* Then $P(\cap A_i) = P(A_1)P(A_2|A_1)...P(A_n|A_1 \cap ... A_{n - 1})$

# Law of Total Probability
* Let $B_1$ through $B_n$ be a partition of $\Omega$
* Let $\cup B_i = \Omega$, $B_i \cap B_j = \emptyset$, $i \neq j$
* Then for any event A, $P(A) = \sum P(A_i|B_i)P(B_i)$

# Example
* A = {Randomly drawn person will vote in the US}
* $B_i$ = {Randomly drawn person resides in state i}, i = 1 through 50
* $P(A) = \sum P(A|B_i)P(B_i)$
* $P(B_i)$ = number of people in state i / number of people in the US

# Example: Occupational Mobility
* Occupations are categorized into 3 groups, upper, middle, and lower
* $u_1$ = {Randomly drawn father's occupation is in u}
* $u_2$ = {Randomly drawn son's occupation is in u}
* $M_1$ = {Randomly drawn father's occupation is in M}
* $M_2$ = {Randomly drawn son's occupation is in M}
* $L_1$ = ...
* $L_2$ = ...
* We are given
* ||$U_2$|$M_2$|$L_2$|
  |---|---|---|---|
  |$U_1$|.45|.48|.07|
  |$M_1$|.05|.7|.25|
  |$L_1$|.01|.5|.49|
* $P(U_1) = .1, P(M_1) = .4, P(L_1) = .5, ...$
* Law of total probability = $P(U_2|U_1)P(U_1)+P(U_2|M_1)P(M_1)+P(U_2|L_1)P(L_1)$
* Partition is $U_1, M_1, L_1$
* Note: $P(U_2) + P(M_2) + P(L_2) = 1$

# How can we flip conditional probabilities?
* eg $P(U_1|U_2)$
* $P(U_1|U_2) = \frac{P(U_1 \cap U_2)}{P(U_2)}$
* Notice $P(U_1 \cap U_2) = P(U_2|U_1)P(U_1)$
* $P(U_1|U_2) = \frac{P(U_2|U_1)P(U_1)}{P(U_2)} = \frac{.45*.1}{.07}$
* This is an illustration of Bayes' rule
* Two formulations
  1. For any events A and B, $P(A),P(B) > 0$
     * We have $P(B|A)=\frac{P(A|B)P(B)}{P(A)}$
     * Note $P(B|A)P(A) = P(A|B)P(B)$
  2. Let $B_1$ to $B_n$ be a partition of $\Omega$
     * Then for my fixed $i \in {1 \to n}$
     * $P(B_i|A) = \frac{P(A|B_i)P(B_i)}{P(A)}$
     * $P(B_i|A) = \frac{P(A|B_i)P(B_i)}{\sum P(A|B_l)P(B_l)}$

# Example: Lie Detector Test
* $L$ = {Person taking the test is lying}
* $T$ = {Person taking the test is telling the truth}
* $D_+$ = {Positive test}
* $D_-$ = {Negative alarm}
* According to manufacturers data, we have $P(D_+|L)=.88$, $P(D_-|L) = .12$, $P(D_+|T)=.14$, $P(D_-|T)=.86$
* Let's try to calculate the probability that the person is telling the truth given that there was a false alarm
* $P(T|D_+) = ?$
* Let's assume $P(T) = .99$, $P(L) = .01$
* $P(T|D_+) = \frac{P(D_+|T)P(T)}{P(D_+)} = \frac{P(D_+|T)P(T)}{P(D_+|T)P(T)+P(D_+|L)P(L)}$
* Probability of a false positive: $P(T|D_+) = .94$
* This is an issue when screening cuz false positives are too high, therefore these lie detector tests are controversial

# Example: Gambler's ruin
* A gambler has k dollars
* They want to win N dollars
* $0 < k < N$
* The gambler plays the following game as many times as necessary until he goes bankrupt or reaching N dollars
* The game is flipping a fair coin where heads implies win $1 and tails implies lose $1
* A = {gambler goes bankrupt}
* Want to calculate $P(A) = ?$
* Use $P_k(A)$ for $P(A)$
* Want to derive a formula for $P_k(A)$ in terms of k and N
* B = {1st toss is heads}

# Techniques "first step analysis"
* $P_k(A) = P_k(A|B)P_k(B) + P_k(A|B^C)P(B^C)$
* Law of total probability with partition $B, B^C$
* $= .5 P_k(A|B) + .5 P_k(A|B^C)$
* $= .5 P_{k+1}(A) + .5 P_{k-1}(A)$
* Let $P_k = P_k(A)$, ie $P_k = .5 P_{k + 1} + .5 P_{k-1}$ for any k
  * This is a recurrence relation
  * $\to 2P_k = P_{k + 1} + P_{k - 1}$
  * $\to P_k - P_{k - 1} = P_{k + 1} - P_k$ for all k
  * Let $b_k = P_k - P_{k - 1}$
  * Key observation: $b_1 = b_2 = ... = c$ where $c$ is a constant 