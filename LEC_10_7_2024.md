# Bayes' Theorem
* Conditional probability: $P(A|B) = \frac{P(A\cap B)}{P(B)}$
* Bayes' Rule: $P(B|A) = \frac{P(A|B) * P(B)}{P(A)}$
* Let $B_1 \to B_n$ be a partition of $\Omega$
  * $P(B_i|A) = \frac{P(A|B_i)P(B_i)}{\Sigma _{l=1}^n P(A|B_l)P(B_l)}$

# Gambler's Ruin
* Gambler has k dollars and wants to have N dollars, 0 < k < N
* Gambler plays following game until they reach N dollars or goes bankrupt
* Each involves tossing a fair coin where head wins 1 dollar and tails lose 1 dollar
* Let $A$ = {the gambler goes bankrupt}

### Q: What is $P(A)$?
* A: $P_k = 1 - \frac{k}{N}$
* Let $B$ = {1st toss is heads}, $k$ = current dollars the gambler has
  * $P_k(A) = P_k(A|B)P(B) + P_k(A|B^c)P(B^c)$
  * $P_k(A) = P_k(A|B) * .5 + P_k(A|B^c) * .5$
  * $P_k(A) = P_{k+1}(A) * .5 + P_{k-1}(A|B^c) * .5$
  * $2P_k = P_{k+1} + P_{k-1}$
  * $P_k - P_{k-1} = P_{k+1} - P_k$
* Let $b_k = P_k - P_{k-1}$
  * $b_k = b_{k+1}$
* All $b_k$'s are the same
  * $P_k = P_{k-1} + (P_k - P_{k-1})$
  * $P_k = P_{k-1} + b$
  * $P_k = P_{k-2} + (P_{k-1} - P_{k-2}) + b$
  * $P_k = P_{k-2} + 2b$
  * ...
  * $P_k = P_0 + kb$
  * $P_k = 1 + kb$
* Need to find $b$
  * $0 - 1 = P_N - P_0 = (P_N - P_{N-1}) + (P_{N-1} - P_{N-2}) + ... + (P_1 - P_0)$
  * Telescoping sum, can replace all terms in between with $b$
  * $-1 = N * b \to b = \frac{-1}{N}$
  * $P_k = 1 - \frac{k}{N}$

# Independent events
* Roughly speaking, we say 2 events are independent if knowing that one has occured doesn't provide any info about the other
* Def: Events $A$ and $B$ are independent if $P(A|B) = P(A),P(B|A) = P(B)$
* Rewrite: $\frac{P(A \cap B)}{P(B)} = P(A)$
  * $P(A \cap B) = P(B)P(A)$

# Example: You have a well shuffled deck of 52 cards and deal one
* $A$ = {dealt card is an ace}
* $D$ = {dealt card is a diamond}

### Q: Are $A$ and $D$ independent?
* A: Yes, lets check
* Need to check $P(A \cap D) = P(A)P(D)$
* Equiprobable assumption: $P(A \cap D) = \frac{|A \cap D|}{|\Omega|}= \frac{1}{52}$
* $P(A) = \frac{4}{52}$
* $P(D) = \frac{13}{52}$
* $P(A)P(D) = \frac{4}{52} * \frac{13}{52} = \frac{1}{52}$

# What about independent among more than 2 events?
* Def: We can say events $A_1 \to A_m$ are independent if:
  * $P(\cap_j A_{ij}) = P(A_{i1})P(A_{i2})...P(A_{im})$
  * for any $i_1 \to i_m$

### Note: It's possible to have events $A,B,C$ such that
  * $A,B$ are independent
  * $A,C$ are independent
  * $B,C$ are independent
  * BUT, it's possible to get info from $C$ from $A \cap B$

### Example: We toss a fair coin twice
* $A$ = {1st toss is head}
* $B$ = {2st toss is head}
* $A$ = {exactly one toss is head}
* Claim $P(C|A \cap B) \neq P(C)$
  * $P(C|A \cap B) = 0$
  * $P(C) = \frac{2}{4} = \frac{1}{2}$

### Example: Suppose everytime someone comes into contact with someone who has a cold, there is a $\frac{1}{8}$ probability you catch it
* Let $C_1 \to C_{10}$ be defined by $C_i$ = {you don't catch cold on $i$-th contact}
* Let $B$ = {you catch cold after 10 contacts}
  * $B = \cup _{i=1}^{10} C_i^c$
  * DeMorgan: $B^c = \cap C_i$
  * $P(B) = 1 - P(B^c) = 1 - P(C_1)P(C_2)...P(C_{10})$
  * $P(B) = 1 - (\frac{7}{8})^{10}$

### Example: Circuit
x|--3--|x

-|-1-2-|-

* The components 1, 2, 3 behave randomly and can work or fail
* $A_i$ = {$i$-th component works}
* $W$ = {circuit works}
* $P(W) =\ ?$
* Assume $P(A_1) = P(A_2) = P(A_3) = p$
  * $W = A_3 \cup (A_1 \cap A_2)$
  * $P(W) = P(A_3) + (A_1 \cap A_2) - P(A_1 \cap A_2 \cap A_3)$
  * $P(W) = p + p^2 - p^3$